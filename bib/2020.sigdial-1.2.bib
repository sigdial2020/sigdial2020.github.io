@InProceedings{shen-EtAl:2020:sigdial,
  author    = {Shen, Siqi  and  Welch, Charles  and  Mihalcea, Rada  and  Pérez-Rosas, Verónica},
  title     = {Counseling-Style Reflection Generation Using Generative Pretrained Transformers with Augmented Context},
  booktitle      = {Proceedings of the 21th Annual Meeting of the Special Interest Group on Discourse and Dialogue},
  month          = {July},
  year           = {2020},
  address        = {1st virtual meeting},
  publisher      = {Association for Computational Linguistics},
  pages     = {10--20},
  abstract  = {We introduce a counseling dialogue system that seeks to assist counselors while they are learning and refining their counseling skills. The system generates counselors’reflections – i.e., responses that reflect back on what the client has said given the dialogue history. Our method builds upon the new generative pretrained transformer architecture and enhances it with context augmentation techniques inspired by traditional strategies used during counselor training. Through a set of comparative experiments, we show that the system that incorporates these strategies performs better in the reflection generation task than a system that is just fine-tuned with counseling conversations. To confirm our findings, we present a human evaluation study that shows that our system generates naturally-looking reflections that are also stylistically and grammatically correct.},
  url       = {https://www.aclweb.org/anthology/2020.sigdial-1.2}
}

